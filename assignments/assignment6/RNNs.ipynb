{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 6: Рекуррентные нейронные сети (RNNs)\n",
    "\n",
    "Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P59NYU98GCb9"
   },
   "outputs": [],
   "source": [
    "#!pip3 -qq install torch==0.4.1\n",
    "#!pip3 -qq install bokeh==0.13.0\n",
    "#!pip3 -qq install gensim\n",
    "#!pip3 -qq install nltk\n",
    "#!pip3 -qq install scikit-learn==0.20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8sVtGHmA9aBM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-6CNKM3b4hT1"
   },
   "source": [
    "# Рекуррентные нейронные сети (RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_XkoGNQUeGm"
   },
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFEtWrS_4rUs"
   },
   "source": [
    "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
    "\n",
    "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
    "\n",
    "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
    "\n",
    "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
    "\n",
    "Мы порешаем сейчас POS Tagging для английского.\n",
    "\n",
    "Будем работать с таким набором тегов:\n",
    "- ADJ - adjective (new, good, high, ...)\n",
    "- ADP - adposition (on, of, at, ...)\n",
    "- ADV - adverb (really, already, still, ...)\n",
    "- CONJ - conjunction (and, or, but, ...)\n",
    "- DET - determiner, article (the, a, some, ...)\n",
    "- NOUN - noun (year, home, costs, ...)\n",
    "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
    "- PRT - particle (at, on, out, ...)\n",
    "- PRON - pronoun (he, their, her, ...)\n",
    "- VERB - verb (is, say, told, ...)\n",
    "- . - punctuation marks (. , ;)\n",
    "- X - other (ersatz, esprit, dunno, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EPIkKdFlHB-X"
   },
   "source": [
    "Скачаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TiA2dGmgF1rW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/yana/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/yana/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d93g_swyJA_V"
   },
   "source": [
    "Пример размеченного предложения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QstS4NO0L97c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The            \tDET\n",
      "Fulton         \tNOUN\n",
      "County         \tNOUN\n",
      "Grand          \tADJ\n",
      "Jury           \tNOUN\n",
      "said           \tVERB\n",
      "Friday         \tNOUN\n",
      "an             \tDET\n",
      "investigation  \tNOUN\n",
      "of             \tADP\n",
      "Atlanta's      \tNOUN\n",
      "recent         \tADJ\n",
      "primary        \tNOUN\n",
      "election       \tNOUN\n",
      "produced       \tVERB\n",
      "``             \t.\n",
      "no             \tDET\n",
      "evidence       \tNOUN\n",
      "''             \t.\n",
      "that           \tADP\n",
      "any            \tDET\n",
      "irregularities \tNOUN\n",
      "took           \tVERB\n",
      "place          \tNOUN\n",
      ".              \t.\n"
     ]
    }
   ],
   "source": [
    "for word, tag in data[0]:\n",
    "    print('{:15}\\t{}'.format(word, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "epdW8u_YXcAv"
   },
   "source": [
    "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
    "\n",
    "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xTai8Ta0lgwL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words count in train set: 739769\n",
      "Words count in val set: 130954\n",
      "Words count in test set: 290469\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
    "\n",
    "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
    "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
    "print('Words count in test set:', sum(len(sent) for sent in test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('``', '.'),\n",
       " ('What', 'DET'),\n",
       " ('did', 'VERB'),\n",
       " ('you', 'PRON'),\n",
       " ('think', 'VERB'),\n",
       " ('about', 'ADP'),\n",
       " (\"Bang-Jensen's\", 'NOUN'),\n",
       " ('contention', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('errors', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('omissions', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('Hungarian', 'ADJ'),\n",
       " ('report', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('?', '.'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eChdLNGtXyP0"
   },
   "source": [
    "Построим маппинги из слов в индекс и из тега в индекс:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCjwwDs6Zq9x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in train = 45441. Tags = {'.', 'X', 'PRT', 'ADJ', 'NOUN', 'ADV', 'NUM', 'PRON', 'CONJ', 'DET', 'ADP', 'VERB'}\n"
     ]
    }
   ],
   "source": [
    "words = {word for sample in train_data for word, tag in sample}\n",
    "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
    "word2ind['<pad>'] = 0\n",
    "\n",
    "tags = {tag for sample in train_data for word, tag in sample}\n",
    "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
    "tag2ind['<pad>'] = 0\n",
    "\n",
    "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URC1B2nvPGFt"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
    "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "bar_width = 0.35\n",
    "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
    "plt.xticks(np.arange(len(tags)), tags)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gArQwbzWWkgi"
   },
   "source": [
    "## Бейзлайн\n",
    "\n",
    "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
    "\n",
    "![tag-context](https://www.nltk.org/images/tag-context.png)  \n",
    "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
    "\n",
    "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
    "\n",
    "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
    "\n",
    "Простейший вариант - униграммная модель, учитывающая только слово:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5rWmSToIaeAo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of unigram tagger = 92.62%\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "\n",
    "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
    "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07Ymb_MkbWsF"
   },
   "source": [
    "Добавим вероятности переходов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjz_Rk0bbMyH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of bigram tagger = 93.42%\n"
     ]
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
    "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uWMw6QHvbaDd"
   },
   "source": [
    "Обратите внимание, что `backoff` важен:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XCuxEBVbOY_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of trigram tagger = 23.33%\n"
     ]
    }
   ],
   "source": [
    "trigram_tagger = nltk.TrigramTagger(train_data)\n",
    "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4t3xyYd__8d-"
   },
   "source": [
    "## Увеличиваем контекст с рекуррентными сетями\n",
    "\n",
    "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
    "\n",
    "Омонимия - основная причина, почему униграмная модель плоха:  \n",
    "*“he cashed a check at the **bank**”*  \n",
    "vs  \n",
    "*“he sat on the **bank** of the river”*\n",
    "\n",
    "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
    "\n",
    "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
    "\n",
    "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
    "\n",
    "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RtRbz1SwgEqc"
   },
   "outputs": [],
   "source": [
    "def convert_data(data, word2ind, tag2ind):\n",
    "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
    "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
    "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
    "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhsTKZalfih6"
   },
   "outputs": [],
   "source": [
    "def iterate_batches(data, batch_size):\n",
    "    X, y = data\n",
    "    n_samples = len(X)\n",
    "\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_indices = indices[start:end]\n",
    "        \n",
    "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
    "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        \n",
    "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
    "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
    "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
    "            \n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l4XsRII5kW5x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 4), (32, 4))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
    "\n",
    "X_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5I9E9P6eFYv"
   },
   "source": [
    "**Задание** Реализуйте `LSTMTagger`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVEHju54d68T"
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tagset_size = tagset_size\n",
    "        self.lstm_layers_count = lstm_layers_count\n",
    "        self.lstm_hidden_dim = lstm_hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, word_emb_dim)\n",
    "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, lstm_layers_count)\n",
    "        self.fc = nn.Linear(lstm_hidden_dim, tagset_size)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        embedded_inputs = self.embedding(inputs)\n",
    "        output, _ = self.lstm(embedded_inputs)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_HA8zyheYGH"
   },
   "source": [
    "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbrxsZ2mehWB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 92)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model(X_batch)\n",
    "\n",
    "def compute_accuracy(pred, target):\n",
    "    _, indices = torch.max(pred, -1)\n",
    "    num_total = torch.sum(target>0).item()\n",
    "    num_cor = torch.sum((indices == target)*(target>0)).item()\n",
    "    return num_cor, num_total\n",
    "\n",
    "compute_accuracy(logits, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5420, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(logits.reshape((-1,len(tag2ind))), y_batch.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSgV3NPUpcjH"
   },
   "source": [
    "**Задание** Вставьте эти вычисление в функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FprPQ0gllo7b"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
    "    epoch_loss = 0\n",
    "    correct_count = 0\n",
    "    sum_count = 0\n",
    "    \n",
    "    is_train = not optimizer is None\n",
    "    name = name or ''\n",
    "    model.train(is_train)\n",
    "    \n",
    "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=batches_count) as progress_bar:\n",
    "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
    "                X_batch, y_batch = LongTensor(X_batch).cuda(), LongTensor(y_batch).cuda()\n",
    "                \n",
    "                logits = model(X_batch)\n",
    "                loss = criterion(logits.reshape((-1, len(tag2ind))), y_batch.view(-1))\n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                if optimizer:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                cur_correct_count, cur_sum_count = compute_accuracy(logits, y_batch)\n",
    "\n",
    "                correct_count += cur_correct_count\n",
    "                sum_count += cur_sum_count\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
    "                )\n",
    "                \n",
    "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
    "            )\n",
    "\n",
    "    return epoch_loss / batches_count, correct_count / sum_count\n",
    "\n",
    "\n",
    "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
    "        val_data=None, val_batch_size=None):\n",
    "        \n",
    "    if not val_data is None and val_batch_size is None:\n",
    "        val_batch_size = batch_size\n",
    "        \n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
    "        \n",
    "        if not val_data is None:\n",
    "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pqfbeh1ltEYa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 10] Train: Loss = 0.68102, Accuracy = 78.36%: 100%|██████████| 572/572 [00:14<00:00, 38.33it/s]\n",
      "[1 / 10]   Val: Loss = 0.35507, Accuracy = 87.94%: 100%|██████████| 13/13 [00:00<00:00, 29.66it/s]\n",
      "[2 / 10] Train: Loss = 0.27232, Accuracy = 90.98%: 100%|██████████| 572/572 [00:14<00:00, 38.74it/s]\n",
      "[2 / 10]   Val: Loss = 0.24706, Accuracy = 91.34%: 100%|██████████| 13/13 [00:00<00:00, 29.49it/s]\n",
      "[3 / 10] Train: Loss = 0.18435, Accuracy = 93.89%: 100%|██████████| 572/572 [00:14<00:00, 38.82it/s]\n",
      "[3 / 10]   Val: Loss = 0.20051, Accuracy = 92.87%: 100%|██████████| 13/13 [00:00<00:00, 29.18it/s]\n",
      "[4 / 10] Train: Loss = 0.13763, Accuracy = 95.41%: 100%|██████████| 572/572 [00:14<00:00, 38.40it/s]\n",
      "[4 / 10]   Val: Loss = 0.17960, Accuracy = 93.60%: 100%|██████████| 13/13 [00:00<00:00, 27.35it/s]\n",
      "[5 / 10] Train: Loss = 0.10732, Accuracy = 96.40%: 100%|██████████| 572/572 [00:14<00:00, 38.47it/s]\n",
      "[5 / 10]   Val: Loss = 0.17529, Accuracy = 94.02%: 100%|██████████| 13/13 [00:00<00:00, 28.15it/s]\n",
      "[6 / 10] Train: Loss = 0.08552, Accuracy = 97.12%: 100%|██████████| 572/572 [00:14<00:00, 38.24it/s]\n",
      "[6 / 10]   Val: Loss = 0.17459, Accuracy = 94.24%: 100%|██████████| 13/13 [00:00<00:00, 27.29it/s]\n",
      "[7 / 10] Train: Loss = 0.06892, Accuracy = 97.68%: 100%|██████████| 572/572 [00:14<00:00, 38.52it/s]\n",
      "[7 / 10]   Val: Loss = 0.17775, Accuracy = 94.32%: 100%|██████████| 13/13 [00:00<00:00, 27.85it/s]\n",
      "[8 / 10] Train: Loss = 0.05607, Accuracy = 98.11%: 100%|██████████| 572/572 [00:14<00:00, 38.28it/s]\n",
      "[8 / 10]   Val: Loss = 0.18626, Accuracy = 94.41%: 100%|██████████| 13/13 [00:00<00:00, 27.54it/s]\n",
      "[9 / 10] Train: Loss = 0.04591, Accuracy = 98.45%: 100%|██████████| 572/572 [00:14<00:00, 38.30it/s]\n",
      "[9 / 10]   Val: Loss = 0.19561, Accuracy = 94.41%: 100%|██████████| 13/13 [00:00<00:00, 28.32it/s]\n",
      "[10 / 10] Train: Loss = 0.03768, Accuracy = 98.76%: 100%|██████████| 572/572 [00:14<00:00, 38.42it/s]\n",
      "[10 / 10]   Val: Loss = 0.19786, Accuracy = 94.49%: 100%|██████████| 13/13 [00:00<00:00, 29.50it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m0qGetIhfUE5"
   },
   "source": [
    "### Masking\n",
    "\n",
    "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
    "\n",
    "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAfV2dEOfHo5"
   },
   "source": [
    "**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98wr38_rw55D"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, batch_size):\n",
    "    loss, acc = do_epoch(model, criterion, data, batch_size, None, 'Eval:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: Loss = 0.19422, Accuracy = 94.57%: 100%|██████████| 28/28 [00:00<00:00, 29.11it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, data=(X_test, y_test), batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PXUTSFaEHbDG"
   },
   "source": [
    "### Bidirectional LSTM\n",
    "\n",
    "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
    "\n",
    "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
    "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
    "\n",
    "**Задание** Добавьте Bidirectional LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZTXmYGD_ANhm"
   },
   "source": [
    "### Предобученные эмбеддинги\n",
    "\n",
    "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
    "\n",
    "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZpY_Q1xZ18h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "w2v_model = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KYogOoKlgtcf"
   },
   "source": [
    "Построим подматрицу для слов из нашей тренировочной выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "known_count = 0\n",
    "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
    "for word, ind in word2ind.items():\n",
    "    word = word.lower()\n",
    "    if word in w2v_model.vocab:\n",
    "        embeddings[ind] = w2v_model.get_vector(word)\n",
    "        known_count += 1\n",
    "        \n",
    "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Know 38736 out of 45441 word embeddings\n"
     ]
    }
   ],
   "source": [
    "known_count = 0\n",
    "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
    "for word, ind in word2ind.items():\n",
    "    word = word.lower()\n",
    "    if word in w2v_model.index_to_key:\n",
    "        embeddings[ind] = w2v_model.get_vector(word)\n",
    "        known_count += 1\n",
    "        \n",
    "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcG7i-R8hbY3"
   },
   "source": [
    "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LxaRBpQd0pat"
   },
   "outputs": [],
   "source": [
    "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
    "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        self.tagset_size = tagset_size\n",
    "        self.lstm_hidden_dim = lstm_hidden_dim\n",
    "        self.lstm_layers_count = lstm_layers_count\n",
    "        \n",
    "        #self.embedding = nn.Embedding.from_pretrained(embeddings)\n",
    "        #_, self.embedding_dim = embeddings.shape\n",
    "        #self.lstm = nn.LSTM(self.embedding_dim, lstm_hidden_dim, lstm_layers_count, bidirectional = True)\n",
    "        self.num_embeddings, self.embedding_dim = embeddings.shape\n",
    "        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_dim)\n",
    "        self.embedding.load_state_dict({'weight': torch.tensor(embeddings)})\n",
    "        self.lstm = nn.LSTM(self.embedding_dim, lstm_hidden_dim, lstm_layers_count, bidirectional = True)\n",
    "        self.fc = nn.Linear(2*lstm_hidden_dim, tagset_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embedded = self.embedding(inputs)\n",
    "        output, _ = self.lstm(embedded)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBtI6BDE-Fc7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 10] Train: Loss = 0.39224, Accuracy = 88.84%: 100%|██████████| 572/572 [00:14<00:00, 38.90it/s]\n",
      "[1 / 10]   Val: Loss = 0.12340, Accuracy = 96.46%: 100%|██████████| 13/13 [00:00<00:00, 38.29it/s]\n",
      "[2 / 10] Train: Loss = 0.07128, Accuracy = 97.80%: 100%|██████████| 572/572 [00:13<00:00, 41.11it/s]\n",
      "[2 / 10]   Val: Loss = 0.09547, Accuracy = 97.17%: 100%|██████████| 13/13 [00:00<00:00, 36.19it/s]\n",
      "[3 / 10] Train: Loss = 0.04588, Accuracy = 98.54%: 100%|██████████| 572/572 [00:13<00:00, 42.55it/s]\n",
      "[3 / 10]   Val: Loss = 0.08738, Accuracy = 97.40%: 100%|██████████| 13/13 [00:00<00:00, 34.52it/s]\n",
      "[4 / 10] Train: Loss = 0.03341, Accuracy = 98.93%: 100%|██████████| 572/572 [00:13<00:00, 42.31it/s]\n",
      "[4 / 10]   Val: Loss = 0.09210, Accuracy = 97.44%: 100%|██████████| 13/13 [00:00<00:00, 36.43it/s]\n",
      "[5 / 10] Train: Loss = 0.02577, Accuracy = 99.18%: 100%|██████████| 572/572 [00:13<00:00, 42.43it/s]\n",
      "[5 / 10]   Val: Loss = 0.08801, Accuracy = 97.51%: 100%|██████████| 13/13 [00:00<00:00, 34.39it/s]\n",
      "[6 / 10] Train: Loss = 0.02022, Accuracy = 99.36%: 100%|██████████| 572/572 [00:13<00:00, 42.30it/s]\n",
      "[6 / 10]   Val: Loss = 0.09581, Accuracy = 97.46%: 100%|██████████| 13/13 [00:00<00:00, 35.87it/s]\n",
      "[7 / 10] Train: Loss = 0.01599, Accuracy = 99.50%: 100%|██████████| 572/572 [00:13<00:00, 42.23it/s] \n",
      "[7 / 10]   Val: Loss = 0.09819, Accuracy = 97.49%: 100%|██████████| 13/13 [00:00<00:00, 33.60it/s]\n",
      "[8 / 10] Train: Loss = 0.01262, Accuracy = 99.61%: 100%|██████████| 572/572 [00:13<00:00, 42.71it/s] \n",
      "[8 / 10]   Val: Loss = 0.10434, Accuracy = 97.44%: 100%|██████████| 13/13 [00:00<00:00, 36.06it/s]\n",
      "[9 / 10] Train: Loss = 0.00967, Accuracy = 99.71%: 100%|██████████| 572/572 [00:13<00:00, 41.95it/s] \n",
      "[9 / 10]   Val: Loss = 0.10934, Accuracy = 97.38%: 100%|██████████| 13/13 [00:00<00:00, 35.25it/s]\n",
      "[10 / 10] Train: Loss = 0.00729, Accuracy = 99.79%: 100%|██████████| 572/572 [00:13<00:00, 42.01it/s] \n",
      "[10 / 10]   Val: Loss = 0.11392, Accuracy = 97.37%: 100%|██████████| 13/13 [00:00<00:00, 37.04it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTaggerWithPretrainedEmbs(\n",
    "    embeddings=embeddings,\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Ne_8f24h8kg"
   },
   "source": [
    "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n",
    "\n",
    "Добейтесь качества лучше прошлых моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPUuAPGhEGVR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: Loss = 0.11477, Accuracy = 97.36%: 100%|██████████| 28/28 [00:00<00:00, 38.46it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, data=(X_test, y_test), batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Week 06 - RNNs, part 2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
