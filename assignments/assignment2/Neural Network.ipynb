{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for param_0\n",
      "Gradient check passed!\n",
      "Checking gradient for param_1\n",
      "Gradient check passed!\n",
      "Checking gradient for param_2\n",
      "Gradient check passed!\n",
      "Checking gradient for param_3\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for param_0\n",
      "Gradient check passed!\n",
      "Checking gradient for param_1\n",
      "Gradient check passed!\n",
      "Checking gradient for param_2\n",
      "Gradient check passed!\n",
      "Checking gradient for param_3\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03333333333333333"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.321296, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302287, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302309, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302296, Train accuracy: 0.114222, val accuracy: 0.147000\n",
      "Loss: 2.302287, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302291, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302295, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302282, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302298, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302294, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302295, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302305, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302292, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302304, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302285, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302285, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302302, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302293, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302306, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302296, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.298767, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278367, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275827, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275258, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274795, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274048, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273080, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272412, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271868, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271732, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271554, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271567, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271614, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271552, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271520, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271582, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271491, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271564, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271416, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271538, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.327623, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317179, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308946, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302443, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297285, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293181, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289901, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287272, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285151, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283435, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282041, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280901, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279968, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279205, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278571, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278047, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277614, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277250, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276944, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276688, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.333185, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.321131, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.309615, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.302288, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.289684, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.277549, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.265176, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.244047, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.214660, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.144939, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.078462, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.030650, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.972499, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.898704, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.883187, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.853652, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.805609, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.802620, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.796832, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.802787, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.806147, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.802753, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.773979, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.771388, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.751491, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.740650, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.764873, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.765348, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.723768, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.713733, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.703159, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.654797, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.643122, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.623959, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.621664, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.585880, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.611254, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.596192, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.591563, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.590447, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.519957, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.533846, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.496478, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.520633, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.492708, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.475518, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.464619, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.434418, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.436341, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.421670, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.417473, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.416258, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.417713, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.421802, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.399504, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.416853, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.403044, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.378030, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.382125, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.414638, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.382794, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.400905, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.377253, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.376103, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.377951, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.366980, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.359657, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.371951, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.366377, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.373581, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.382708, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.393671, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.393773, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.363070, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.365872, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.351731, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.362317, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.348325, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.352235, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.355080, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.348986, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.343236, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.351831, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.340553, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.368468, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.360927, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.349890, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.355845, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.336665, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.314775, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.324046, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.315039, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.318284, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.342270, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.323468, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.300722, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.308265, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.323190, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.312791, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.299737, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.292329, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.321133, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.293394, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.299737, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.289965, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.286537, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.295410, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.281795, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.278691, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.276420, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.283379, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.270669, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.284524, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.291953, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.269233, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.293862, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.275364, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.272855, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.264019, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.273228, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.270534, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.250816, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.275165, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.281775, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.274400, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.284967, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.263617, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.280321, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.251783, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.256686, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.269847, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.262675, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.253482, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.259824, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.275360, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.268775, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.261295, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.270226, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.258000, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.242129, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.244655, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.248644, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.248025, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.257787, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.265747, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.273436, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.263657, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.249640, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.255827, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.261365, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.303352, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.283800, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.248107, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.187479, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.036930, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.796584, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.568374, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.411622, Train accuracy: 0.400000, val accuracy: 0.133333\n",
      "Loss: 1.934208, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.428324, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 0.943366, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 0.940091, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.454389, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.416284, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.123907, Train accuracy: 0.933333, val accuracy: 0.133333\n",
      "Loss: 0.212486, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.114617, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.132054, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.155102, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.160498, Train accuracy: 1.000000, val accuracy: 0.066667\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 300, reg = 1e-3)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=5e-1, num_epochs=20, batch_size=30)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.303546, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.283901, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.247534, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.182698, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.017151, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.822291, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.601254, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.539838, Train accuracy: 0.400000, val accuracy: 0.133333\n",
      "Loss: 1.666967, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.493501, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.293811, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 0.895603, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.502814, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.326650, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.242605, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.184793, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.132079, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.129781, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.145528, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.161207, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-3a02a99da503>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best validation accuracy achieved: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbest_val_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = [1e-4]\n",
    "reg_strength = [1e-3]\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 300, reg = 1e-3)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=5e-1, num_epochs=20, batch_size=30)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb56f7e3110>]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-83c278478367>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulticlass_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Neural net test set accuracy: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
